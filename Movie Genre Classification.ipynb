{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import xrange\n",
    "from tempfile import gettempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"wiki_movie_plots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step one: Convert plot to vectorized sequence of words.\n",
    "\n",
    "Step two: Set up LSTM to generate predictions.\n",
    "\n",
    "Step three: Interpret predictions.\n",
    "\n",
    "Ideas:\n",
    "- Predictions at every word (or sentence, or paragraph), see where they change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_to_consider = [\"drama\", \"comedy\", \"horror\", \"action\", \"thriller\", \"romance\", \"western\"]\n",
    "movies = movies[movies['Genre'].isin(genres_to_consider)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5841</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4347</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1124</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1087</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thriller</th>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>955</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>918</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>western</th>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>864</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Release Year  Title  Origin/Ethnicity  Director  Cast  Wiki Page  \\\n",
       "Genre                                                                        \n",
       "drama             5964   5964              5964      5964  5841       5964   \n",
       "comedy            4379   4379              4379      4379  4347       4379   \n",
       "horror            1167   1167              1167      1167  1124       1167   \n",
       "action            1098   1098              1098      1098  1087       1098   \n",
       "thriller           966    966               966       966   955        966   \n",
       "romance            923    923               923       923   918        923   \n",
       "western            865    865               865       865   864        865   \n",
       "\n",
       "          Plot  \n",
       "Genre           \n",
       "drama     5964  \n",
       "comedy    4379  \n",
       "horror    1167  \n",
       "action    1098  \n",
       "thriller   966  \n",
       "romance    923  \n",
       "western    865  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.groupby('Genre').count().sort_values(\"Title\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1907</td>\n",
       "      <td>How Brown Saw the Baseball Game</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/How_Brown_Saw_th...</td>\n",
       "      <td>Before heading out to a baseball game at a nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1907</td>\n",
       "      <td>Laughing Gas</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>Bertha Regustus, Edward Boulden</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Laughing_Gas_(fi...</td>\n",
       "      <td>The plot is that of a black woman going to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1908</td>\n",
       "      <td>The Adventures of Dollie</td>\n",
       "      <td>American</td>\n",
       "      <td>D. W. Griffith</td>\n",
       "      <td>Arthur V. Johnson, Linda Arvidson</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>On a beautiful summer day a father and mother ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Year                            Title Origin/Ethnicity  \\\n",
       "6           1903          The Great Train Robbery         American   \n",
       "7           1904                  The Suburbanite         American   \n",
       "14          1907  How Brown Saw the Baseball Game         American   \n",
       "15          1907                     Laughing Gas         American   \n",
       "16          1908         The Adventures of Dollie         American   \n",
       "\n",
       "                Director                               Cast    Genre  \\\n",
       "6        Edwin S. Porter                                NaN  western   \n",
       "7     Wallace McCutcheon                                NaN   comedy   \n",
       "14               Unknown                            Unknown   comedy   \n",
       "15  Edwin Stanton Porter    Bertha Regustus, Edward Boulden   comedy   \n",
       "16        D. W. Griffith  Arthur V. Johnson, Linda Arvidson    drama   \n",
       "\n",
       "                                            Wiki Page  \\\n",
       "6   https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7       https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "14  https://en.wikipedia.org/wiki/How_Brown_Saw_th...   \n",
       "15  https://en.wikipedia.org/wiki/Laughing_Gas_(fi...   \n",
       "16  https://en.wikipedia.org/wiki/The_Adventures_o...   \n",
       "\n",
       "                                                 Plot  \n",
       "6   The film opens with two bandits breaking into ...  \n",
       "7   The film is about a family who move to the sub...  \n",
       "14  Before heading out to a baseball game at a nea...  \n",
       "15  The plot is that of a black woman going to the...  \n",
       "16  On a beautiful summer day a father and mother ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.sample(frac=1) # Shuffles the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 600\n",
    "N_test = 200\n",
    "\n",
    "train = None\n",
    "test = None\n",
    "\n",
    "train = movies[movies['Genre'] == 'drama'][:N_train]\n",
    "test = movies[movies['Genre'] == 'drama'][N_train:]\n",
    "\n",
    "for genre in genres_to_consider[1:]:\n",
    "    tr = movies[movies['Genre'] == genre][:N_train]\n",
    "    te = movies[movies['Genre'] == genre][N_train:]\n",
    "    train = pd.concat([train, tr])\n",
    "    test = pd.concat([test, te])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16447</th>\n",
       "      <td>2013</td>\n",
       "      <td>Big Sur</td>\n",
       "      <td>American</td>\n",
       "      <td>Michael Polish</td>\n",
       "      <td>Josh Lucas, Jean-Marc Barr, Radha Mitchell</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Big_Sur_(film)</td>\n",
       "      <td>Jack Kerouac, coming off the recent success of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17591</th>\n",
       "      <td>1989</td>\n",
       "      <td>Bangkok Hilton</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Ken Cameron</td>\n",
       "      <td>Nicole Kidman, Denholm Elliott, Hugo Weaving, ...</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bangkok_Hilton</td>\n",
       "      <td>Bangkok Hilton begins as Hal Stanton (Denholm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>1954</td>\n",
       "      <td>Hell and High Water</td>\n",
       "      <td>American</td>\n",
       "      <td>Samuel Fuller</td>\n",
       "      <td>Richard Widmark, Bella Darvi</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hell_and_High_Wa...</td>\n",
       "      <td>In 1953, renowned French scientist Professor M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1919</td>\n",
       "      <td>True Heart Susie</td>\n",
       "      <td>American</td>\n",
       "      <td>D.W. Griffith</td>\n",
       "      <td>Lillian Gish, Bobby Harron</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/True_Heart_Susie</td>\n",
       "      <td>As described in a film magazine,[2] \"True Hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32066</th>\n",
       "      <td>2000</td>\n",
       "      <td>Kalisundam Raa</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>Udayasankar</td>\n",
       "      <td>Venkatesh, Simran</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kalisundam_Raa</td>\n",
       "      <td>Raghaviah (K. Vishwanath) and Ram Mohan Rao (R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                Title Origin/Ethnicity        Director  \\\n",
       "16447          2013              Big Sur         American  Michael Polish   \n",
       "17591          1989       Bangkok Hilton       Australian     Ken Cameron   \n",
       "6106           1954  Hell and High Water         American   Samuel Fuller   \n",
       "299            1919     True Heart Susie         American   D.W. Griffith   \n",
       "32066          2000       Kalisundam Raa           Telugu     Udayasankar   \n",
       "\n",
       "                                                    Cast  Genre  \\\n",
       "16447         Josh Lucas, Jean-Marc Barr, Radha Mitchell  drama   \n",
       "17591  Nicole Kidman, Denholm Elliott, Hugo Weaving, ...  drama   \n",
       "6106                        Richard Widmark, Bella Darvi  drama   \n",
       "299                           Lillian Gish, Bobby Harron  drama   \n",
       "32066                                  Venkatesh, Simran  drama   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "16447       https://en.wikipedia.org/wiki/Big_Sur_(film)   \n",
       "17591       https://en.wikipedia.org/wiki/Bangkok_Hilton   \n",
       "6106   https://en.wikipedia.org/wiki/Hell_and_High_Wa...   \n",
       "299       https://en.wikipedia.org/wiki/True_Heart_Susie   \n",
       "32066       https://en.wikipedia.org/wiki/Kalisundam_Raa   \n",
       "\n",
       "                                                    Plot  \n",
       "16447  Jack Kerouac, coming off the recent success of...  \n",
       "17591  Bangkok Hilton begins as Hal Stanton (Denholm ...  \n",
       "6106   In 1953, renowned French scientist Professor M...  \n",
       "299    As described in a film magazine,[2] \"True Hear...  \n",
       "32066  Raghaviah (K. Vishwanath) and Ram Mohan Rao (R...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings Using Word2Vec on Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"(\" : \" ( \",\n",
    "    \")\" : \" ) \",\n",
    "    \"-\" : \" - \",\n",
    "    \",\" : \" , \",\n",
    "    \"\\n\" : \"\",\n",
    "    \"\\r\" : \"\",\n",
    "    \"\\\"\" : \" \\\" \",\n",
    "    \"'\" : \" ' \",\n",
    "    \".\" : \" . \",\n",
    "    \";\" : \" ; \",\n",
    "    \":\" : \" : \",\n",
    "    \"ENDOFARTICLE\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace various characters in a single pass over text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(d, text):\n",
    "    \n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, d.keys())))\n",
    "    \n",
    "    return regex.sub(lambda x: d[x.string[x.start():x.end()]], text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parses (k) available wikipedia files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 164\n",
      "Files being used: 100\n"
     ]
    }
   ],
   "source": [
    "filename = \"wiki\"\n",
    "words = []\n",
    "k = 100\n",
    "\n",
    "files_in_directory = os.listdir(filename)\n",
    "print(\"Files in directory: \" + str(len(files_in_directory)))\n",
    "print(\"Files being used: \" + str(k))\n",
    "\n",
    "for file in files_in_directory[:k]:\n",
    "    f = open(filename + \"/\" + file, 'r', encoding = \"ISO-8859-1\")\n",
    "    f = f.read()\n",
    "    f = multiple_replace(d, f)\n",
    "    f = re.sub(\"<doc.{20,150}>\", \"\", f) # Gets rid of intro \n",
    "    f = re.sub(\"</doc>\", \"\", f) # Gets rid of end\n",
    "    f = re.sub(\"\\[[0-9]+\\]\", \"\", f) # Gets rid of reference pointers \n",
    "    f = re.sub(\" [A-Z]{1}[A-Z]+ \", \" \", f)\n",
    "    all_words = f.split(\" \")\n",
    "    for word in all_words:\n",
    "        words.append(word.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate vocabulary instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(words, n_words):\n",
    "    word_count = [[\"UNK\", -1]]\n",
    "    word_count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    \n",
    "    d = {}\n",
    "    for w, _ in word_count:\n",
    "        d[w] = len(d)\n",
    "        \n",
    "    data = []\n",
    "    num_unks = 0\n",
    "    for w in words:\n",
    "        index = d.get(w, 0)\n",
    "        if index == 0:\n",
    "            num_unks += 1\n",
    "        data.append(index)\n",
    "            \n",
    "    word_count[0][1] = num_unks\n",
    "    \n",
    "    reversed_dictionary = dict(zip(d.values(), d.keys()))\n",
    "    \n",
    "    return data, word_count, d, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 50000 # Subject to change \n",
    "data, word_count, vocab_dictionary, reversed_dictionary = build_batch(words, n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates a batch of wikipedia data to be used for the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def generate_batch(batch_size, data, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "    if data_index + span > len(data):\n",
    "        data_index = 0\n",
    "    buffer.extend(data[data_index:data_index + span])\n",
    "    data_index += span\n",
    "    for i in range(batch_size // num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "            \n",
    "        if data_index == len(data):\n",
    "            buffer.extend(data[0:span])\n",
    "            data_index = span\n",
    "        else:\n",
    "            buffer.append(data[data_index])\n",
    "            data_index += 1\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "embedding_size = 128\n",
    "skip_window = 1\n",
    "num_skips = 2\n",
    "num_sampled = 64\n",
    "\n",
    "valid_size = 16\n",
    "valid_window = 100\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    with tf.name_scope('embeddings'):\n",
    "        embeddings = tf.Variable(\n",
    "            tf.random_uniform([n_words, embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "    \n",
    "    with tf.name_scope(\"weights\"):\n",
    "        \n",
    "        nce_weights = tf.Variable(tf.truncated_normal([n_words, embedding_size],\n",
    "                                stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        \n",
    "    with tf.name_scope('biases'):\n",
    "        \n",
    "        nce_biases = tf.Variable(tf.zeros([n_words]))\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "      loss = tf.reduce_mean(\n",
    "          tf.nn.nce_loss(\n",
    "              weights=nce_weights,\n",
    "              biases=nce_biases,\n",
    "              labels=train_labels,\n",
    "              inputs=embed,\n",
    "              num_sampled=num_sampled,\n",
    "              num_classes=n_words))\n",
    "    \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
    "                                              valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "        valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model to obtain embeddings for each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 250001 # Can increase \n",
    "log_dir = \"182/LSTMsAndInterpretability\"\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    writer = tf.summary.FileWriter(log_dir, session.graph)\n",
    "    \n",
    "    init.run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    average_loss = 0\n",
    "    for step in range(n_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size,\n",
    "                                                  data,\n",
    "                                                  num_skips,\n",
    "                                                  skip_window)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "        \n",
    "        run_metadata = tf.RunMetadata()\n",
    "    \n",
    "        _, summary, loss_val = session.run([optimizer, merged, loss],\n",
    "                                         feed_dict=feed_dict,\n",
    "                                         run_metadata=run_metadata)\n",
    "    \n",
    "        average_loss += loss_val\n",
    "    \n",
    "        if step % 5000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 5000\n",
    "            # The average loss is an estimate of the loss over the last 5000\n",
    "            # batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss)\n",
    "            average_loss = 0\n",
    "            \n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "        \n",
    "    with open(log_dir + '/metadata.tsv', 'w') as f:\n",
    "        for i in range(n_words):\n",
    "            f.write(reversed_dictionary[i] + '\\n')\n",
    "        \n",
    "    saver.save(session, os.path.join(log_dir, 'model.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computes cosine similarity between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function finds the closest word embeddings to a given word and returns their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(embeddings, word, index_to_word, word_to_index, n_words, count):\n",
    "    assert word in word_to_index, 'Unknown word'\n",
    "    \n",
    "    print(\"Word occurs: \" + str(count[word_to_index[word]][1]) + \" times.\\n\")\n",
    "    \n",
    "    word_embedding = embeddings[word_to_index.get(word)]\n",
    "    \n",
    "    distances = np.sum((embeddings - word_embedding) ** 2, axis=1)\n",
    "    \n",
    "    indices = np.argsort(distances)[:n_words]\n",
    "    for i in indices:\n",
    "        print(index_to_word.get(i, \"UNK\"))\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest(final_embeddings, \"jesus\", reversed_dictionary, vocab_dictionary, 20, word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots TSNE for most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels, filename):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    plt.figure(figsize=(18, 18))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy = (x, y), xytext = (5, 2), textcoords = 'offset points', ha='right', va='bottom')\n",
    "        \n",
    "try:\n",
    "    # pylint: disable=g-import-not-at-top\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    tsne = TSNE(\n",
    "        perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "    plot_only = 500\n",
    "    low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "    labels = [reversed_dictionary[i] for i in xrange(plot_only)]\n",
    "    plot_with_labels(low_dim_embs, labels, os.path.join(gettempdir(),\n",
    "                                                        'tsne.png'))\n",
    "\n",
    "except ImportError as ex:\n",
    "    print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to encode the genre to be used for LSTM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(df, col, label_col=\"Label\"):\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[label_col] = df[col].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = encodeLabel(train, \"Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot_words = train['Plot'].tolist()\n",
    "train_labels = train['Label'].tolist()\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps each word in a given plot to its embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(plot_list, final_embeddings):\n",
    "    plot_embeddings = []\n",
    "    \n",
    "    for plot in plot_list:\n",
    "    \n",
    "        embeddings = []\n",
    "    \n",
    "        p = multiple_replace(d, plot)\n",
    "    \n",
    "        all_words = p.split(\" \")\n",
    "    \n",
    "        for word in all_words:\n",
    "        \n",
    "            index = vocab_dictionary.get(word, 0)\n",
    "        \n",
    "            embedding = final_embeddings[index]\n",
    "            embeddings.append(embedding)\n",
    "            \n",
    "        plot_embeddings.append(embeddings)\n",
    "        \n",
    "    return plot_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot_embeddings = get_embeddings(train_plot_words, final_embeddings)\n",
    "train_plot_embeddings = np.array(train_plot_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates a batch of movies to be used for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_movies(batch_size, plots, labels):\n",
    "    # Assert ndarrays \n",
    "    \n",
    "    total = len(plots)\n",
    "    \n",
    "    indices = np.random.choice(total, batch_size, replace=False)\n",
    "    \n",
    "    batch_plots = np.take(plots, indices)\n",
    "    batch_labels = np.take(labels, indices)\n",
    "    \n",
    "    return batch_plots, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs, batch_labels = generate_batch_movies(20, train_plot_embeddings, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel():\n",
    "    \n",
    "    def __init__(self, rnn_size, output_size, learning_rate=1e-4):\n",
    "\n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, None, embedding_size])\n",
    "        self.labels = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "    \n",
    "        lm_cell = tf.nn.rnn_cell.LSTMCell(rnn_size)\n",
    "    \n",
    "        outputs, states = tf.nn.dynamic_rnn(lm_cell, self.inputs, dtype=tf.float32)\n",
    "    \n",
    "        self.output_logits = tf.layers.dense(outputs, output_size)\n",
    "    \n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(self.labels, self.output_logits)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        \n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "        self.saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/JeffyLands/182/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # This is so that when you debug, you reset the graph each time you run this, in essence, cleaning the board\n",
    "model = LSTMModel(256, 7, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "batch_size = 20\n",
    "for i in range(10):\n",
    "    \n",
    "    batch_inputs, batch_labels = generate_batch_movies(batch_size, train_plot_embeddings, train_labels)\n",
    "    \n",
    "    feed_dict = {model.inputs: batch_inputs, model.labels: batch_labels}\n",
    "    \n",
    "    loss, _ = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_dictionary.json', 'w') as fp:\n",
    "    json.dump(vocab_dictionary, fp)\n",
    "with open('reversed_dictionary.json', 'w') as fp:\n",
    "    json.dump(reversed_dictionary, fp)\n",
    "with open('wordcount.json', 'w') as fp:\n",
    "    json.dump(word_count, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 15430244,\n",
       " '': 59041086,\n",
       " 'the': 19802872,\n",
       " '.': 19606110,\n",
       " ',': 18339344,\n",
       " 'of': 10250348,\n",
       " 'and': 8018020,\n",
       " 'in': 7361301,\n",
       " ';': 7097066,\n",
       " 'a': 6166615,\n",
       " '-': 5854060,\n",
       " 'to': 5755138,\n",
       " ')': 4616133,\n",
       " '(': 4612980,\n",
       " '\"': 3735775,\n",
       " 'is': 3350666,\n",
       " 'was': 2942168,\n",
       " \"'\": 2693478,\n",
       " 'for': 2378036,\n",
       " ':': 2270358,\n",
       " 'as': 2242207,\n",
       " 's': 2194936,\n",
       " 'on': 2022034,\n",
       " 'by': 2009159,\n",
       " 'with': 1920241,\n",
       " 'he': 1628851,\n",
       " 'that': 1622900,\n",
       " 'from': 1526793,\n",
       " 'it': 1426551,\n",
       " 'at': 1380414,\n",
       " 'his': 1378255,\n",
       " 'an': 1101848,\n",
       " 'are': 1027211,\n",
       " 'were': 887042,\n",
       " 'this': 886377,\n",
       " 'or': 875241,\n",
       " 'which': 852307,\n",
       " 'be': 851776,\n",
       " 'also': 845684,\n",
       " 'has': 742065,\n",
       " 'one': 657517,\n",
       " 'had': 614012,\n",
       " 'not': 600311,\n",
       " 'first': 589432,\n",
       " 'but': 583710,\n",
       " 'new': 579807,\n",
       " 'their': 575491,\n",
       " 'who': 551742,\n",
       " 'they': 548684,\n",
       " 'have': 535416,\n",
       " 'its': 507148,\n",
       " 'after': 487937,\n",
       " 'other': 471892,\n",
       " 'all': 464436,\n",
       " 'her': 459248,\n",
       " '1': 454320,\n",
       " 'two': 443031,\n",
       " 'there': 430888,\n",
       " 'she': 427902,\n",
       " 'when': 427703,\n",
       " 'been': 415549,\n",
       " '2': 396454,\n",
       " 'time': 384664,\n",
       " 'more': 367199,\n",
       " 'into': 363145,\n",
       " 'external': 354025,\n",
       " 'most': 345716,\n",
       " 'i': 337352,\n",
       " 'can': 337113,\n",
       " 'some': 334790,\n",
       " 'only': 331624,\n",
       " 'links': 331055,\n",
       " '3': 329091,\n",
       " 'school': 327578,\n",
       " 'up': 323030,\n",
       " 'years': 322767,\n",
       " '||': 322336,\n",
       " 'city': 320457,\n",
       " 'many': 312334,\n",
       " 'during': 311255,\n",
       " 'over': 306704,\n",
       " 'world': 306117,\n",
       " 'out': 305441,\n",
       " 'used': 290238,\n",
       " 'may': 288190,\n",
       " 'no': 286846,\n",
       " '0': 286649,\n",
       " 'about': 284695,\n",
       " 'him': 282726,\n",
       " 'see': 280561,\n",
       " 'such': 279649,\n",
       " '5': 273074,\n",
       " 'would': 272468,\n",
       " 'known': 264384,\n",
       " 'american': 263751,\n",
       " '4': 261907,\n",
       " 'united': 259510,\n",
       " 'under': 258042,\n",
       " '2006': 256155,\n",
       " 'where': 253081,\n",
       " 'university': 250636,\n",
       " 'state': 248389,\n",
       " 'then': 243336,\n",
       " 'these': 241564,\n",
       " 'than': 239725,\n",
       " 'between': 236200,\n",
       " 'made': 235904,\n",
       " 'states': 235260,\n",
       " 'later': 235122,\n",
       " 'year': 232846,\n",
       " 'will': 226983,\n",
       " 'war': 225162,\n",
       " 'them': 224493,\n",
       " 'however': 224365,\n",
       " 'part': 222599,\n",
       " 'age': 220673,\n",
       " 'three': 220557,\n",
       " 'name': 220496,\n",
       " 'being': 218411,\n",
       " 'well': 218299,\n",
       " 'national': 214707,\n",
       " 'people': 214079,\n",
       " '2005': 213196,\n",
       " 'while': 212433,\n",
       " 'high': 209883,\n",
       " 'born': 208146,\n",
       " 'history': 205250,\n",
       " 'south': 204461,\n",
       " 'series': 203255,\n",
       " 'through': 201037,\n",
       " 'de': 199736,\n",
       " 'both': 197973,\n",
       " 'became': 197931,\n",
       " 'north': 195605,\n",
       " 'county': 194974,\n",
       " '&': 193895,\n",
       " 'area': 193568,\n",
       " 'john': 192731,\n",
       " '6': 191818,\n",
       " '8': 190201,\n",
       " 'including': 189721,\n",
       " 'before': 188805,\n",
       " 'so': 186919,\n",
       " 'music': 186730,\n",
       " 'called': 184089,\n",
       " 't': 183201,\n",
       " 'if': 180960,\n",
       " 'game': 180279,\n",
       " 'second': 176934,\n",
       " 'since': 176798,\n",
       " 'family': 176727,\n",
       " 'population': 175813,\n",
       " 'town': 175668,\n",
       " 'life': 173596,\n",
       " 'like': 171353,\n",
       " 'now': 169742,\n",
       " 'd': 169391,\n",
       " '2000': 169264,\n",
       " 'group': 169168,\n",
       " 'you': 168634,\n",
       " '2004': 167972,\n",
       " 'film': 167825,\n",
       " 'several': 167596,\n",
       " '7': 167051,\n",
       " 'number': 165669,\n",
       " 'references': 165409,\n",
       " 'use': 165159,\n",
       " 'any': 164195,\n",
       " 'early': 163923,\n",
       " '18': 163891,\n",
       " 'm': 163550,\n",
       " 'until': 162721,\n",
       " 'team': 161694,\n",
       " 'work': 161262,\n",
       " 'c': 160039,\n",
       " 'day': 154810,\n",
       " 'each': 152810,\n",
       " 'u': 152377,\n",
       " 'same': 151591,\n",
       " 'against': 151495,\n",
       " 'west': 151255,\n",
       " 'general': 151011,\n",
       " 'house': 150557,\n",
       " '10': 150440,\n",
       " 'system': 150005,\n",
       " 'york': 149985,\n",
       " 'album': 149834,\n",
       " 'company': 148066,\n",
       " 'line': 146974,\n",
       " 'based': 146682,\n",
       " 'government': 145729,\n",
       " 'because': 144022,\n",
       " 'very': 143890,\n",
       " 'often': 142370,\n",
       " '000': 142354,\n",
       " 'british': 140811,\n",
       " '2001': 140275,\n",
       " 'band': 140056,\n",
       " 'long': 139052,\n",
       " 'back': 138371,\n",
       " '2003': 138067,\n",
       " 'best': 137830,\n",
       " 'located': 137715,\n",
       " 'party': 136935,\n",
       " 'list': 136730,\n",
       " 'four': 136511,\n",
       " 'b': 135484,\n",
       " 'official': 135303,\n",
       " 'home': 135269,\n",
       " 'king': 135244,\n",
       " 'show': 134955,\n",
       " 'e': 134870,\n",
       " 'end': 134863,\n",
       " 'those': 133487,\n",
       " 'bar': 133428,\n",
       " 'international': 131987,\n",
       " '9': 131912,\n",
       " 'released': 131173,\n",
       " 'college': 130214,\n",
       " 'although': 130037,\n",
       " 'place': 129587,\n",
       " 'around': 129154,\n",
       " 'following': 129140,\n",
       " 'what': 127839,\n",
       " 'another': 127277,\n",
       " 'east': 127010,\n",
       " 'century': 125506,\n",
       " 'river': 125326,\n",
       " 'season': 124665,\n",
       " 'major': 124413,\n",
       " 'man': 124402,\n",
       " 'old': 124149,\n",
       " '2002': 123877,\n",
       " 'station': 123446,\n",
       " 'district': 123422,\n",
       " 'great': 122834,\n",
       " 'played': 122824,\n",
       " 'even': 122821,\n",
       " 'book': 122539,\n",
       " 'public': 122489,\n",
       " 'could': 122355,\n",
       " 'still': 122172,\n",
       " 'small': 121515,\n",
       " 'named': 121233,\n",
       " 'order': 121068,\n",
       " 'september': 121044,\n",
       " 'english': 120811,\n",
       " 'large': 119804,\n",
       " 'site': 119776,\n",
       " 'much': 119740,\n",
       " 'right': 119490,\n",
       " 'found': 119381,\n",
       " 'own': 119144,\n",
       " 'member': 118778,\n",
       " '|': 118507,\n",
       " 'members': 118343,\n",
       " 'song': 117816,\n",
       " 'off': 117449,\n",
       " 'former': 117431,\n",
       " 'march': 117332,\n",
       " 'october': 116371,\n",
       " 'january': 116334,\n",
       " 'left': 116314,\n",
       " '12': 116230,\n",
       " 'church': 116091,\n",
       " 'power': 115741,\n",
       " 'white': 114377,\n",
       " 'did': 114133,\n",
       " 'death': 113837,\n",
       " 'st': 112649,\n",
       " 'service': 112260,\n",
       " 'last': 111762,\n",
       " 'do': 111753,\n",
       " 'december': 111328,\n",
       " 'president': 110983,\n",
       " 'website': 110326,\n",
       " 'air': 110275,\n",
       " 'main': 110123,\n",
       " '20': 109409,\n",
       " 'way': 109288,\n",
       " 'set': 109127,\n",
       " 'form': 108905,\n",
       " 'player': 108335,\n",
       " 'text': 108055,\n",
       " 'august': 107915,\n",
       " 'park': 107843,\n",
       " 'children': 107269,\n",
       " 'local': 106803,\n",
       " 'due': 106786,\n",
       " 'november': 106734,\n",
       " 'began': 106656,\n",
       " 'down': 106627,\n",
       " 'june': 106331,\n",
       " 'july': 106155,\n",
       " 'league': 105248,\n",
       " 'won': 104982,\n",
       " 'original': 104825,\n",
       " 'april': 104499,\n",
       " 'law': 104221,\n",
       " 'every': 104071,\n",
       " 'along': 104022,\n",
       " 'include': 103940,\n",
       " '1999': 103427,\n",
       " 'just': 103297,\n",
       " 'black': 101377,\n",
       " 'single': 100630,\n",
       " 'times': 100150,\n",
       " 'living': 100052,\n",
       " 'club': 100043,\n",
       " '15': 99881,\n",
       " 'london': 99204,\n",
       " 'different': 98637,\n",
       " 'french': 98547,\n",
       " '11': 98419,\n",
       " 'within': 98390,\n",
       " 'water': 97912,\n",
       " 'built': 97396,\n",
       " 'we': 96960,\n",
       " 'version': 96948,\n",
       " 'island': 96873,\n",
       " 'p': 96439,\n",
       " 'games': 96362,\n",
       " 'career': 96283,\n",
       " 'army': 96220,\n",
       " 'country': 96030,\n",
       " 'took': 95561,\n",
       " '25': 95342,\n",
       " 'j': 94773,\n",
       " 'make': 94142,\n",
       " 'village': 94027,\n",
       " 'men': 93553,\n",
       " 'center': 93448,\n",
       " 'son': 93102,\n",
       " 'though': 92861,\n",
       " 'non': 92321,\n",
       " 'road': 92027,\n",
       " 'o': 91794,\n",
       " '1998': 91789,\n",
       " 'february': 91737,\n",
       " '30': 91693,\n",
       " 'information': 91631,\n",
       " 'land': 91549,\n",
       " '24': 91396,\n",
       " 'died': 91387,\n",
       " 'near': 91232,\n",
       " 'published': 91132,\n",
       " 'popular': 91025,\n",
       " 'point': 90790,\n",
       " '100': 90232,\n",
       " 'five': 90231,\n",
       " 'side': 89958,\n",
       " 'top': 89819,\n",
       " 'present': 89697,\n",
       " 'television': 89650,\n",
       " 'german': 89534,\n",
       " 'battle': 89257,\n",
       " 'held': 89224,\n",
       " 'father': 88748,\n",
       " 'again': 88633,\n",
       " 'among': 88551,\n",
       " 'england': 88429,\n",
       " 'radio': 87889,\n",
       " 'play': 87877,\n",
       " 'community': 87318,\n",
       " 'according': 87057,\n",
       " 'football': 86977,\n",
       " 'become': 86964,\n",
       " 'political': 86885,\n",
       " 'late': 86493,\n",
       " '1997': 86338,\n",
       " 'live': 85899,\n",
       " '14': 85554,\n",
       " 'act': 85554,\n",
       " 'students': 85316,\n",
       " 'average': 85268,\n",
       " 'central': 85236,\n",
       " 'third': 85221,\n",
       " 'william': 85143,\n",
       " 'income': 85113,\n",
       " 'l': 84978,\n",
       " 'given': 84779,\n",
       " 'final': 84661,\n",
       " 'using': 84485,\n",
       " 'character': 84366,\n",
       " '16': 84323,\n",
       " 'take': 84286,\n",
       " 'few': 84052,\n",
       " 'various': 84039,\n",
       " 'street': 83703,\n",
       " 'love': 83504,\n",
       " 'james': 83017,\n",
       " 'story': 82860,\n",
       " '13': 82851,\n",
       " 'r': 82180,\n",
       " 'art': 82126,\n",
       " 'g': 82043,\n",
       " 'served': 81905,\n",
       " 'george': 81903,\n",
       " 'usually': 81804,\n",
       " '1996': 81739,\n",
       " 'class': 81722,\n",
       " 'western': 81632,\n",
       " 'military': 81309,\n",
       " 'example': 81033,\n",
       " 'red': 81003,\n",
       " 'canada': 80743,\n",
       " 'young': 80631,\n",
       " 'little': 80325,\n",
       " 'force': 80257,\n",
       " 'language': 80113,\n",
       " 'development': 80047,\n",
       " 'building': 79781,\n",
       " 'short': 79750,\n",
       " 'without': 79499,\n",
       " 'together': 79474,\n",
       " 'currently': 79228,\n",
       " 'written': 79130,\n",
       " 'la': 79107,\n",
       " 'said': 79061,\n",
       " 'rock': 79025,\n",
       " 'episode': 78553,\n",
       " 'never': 78506,\n",
       " 'head': 78244,\n",
       " 'created': 78159,\n",
       " 'david': 77870,\n",
       " 'works': 77637,\n",
       " 'once': 77241,\n",
       " 'x': 77205,\n",
       " 'came': 77179,\n",
       " 'america': 77160,\n",
       " 'title': 77092,\n",
       " 'common': 76845,\n",
       " 'my': 76758,\n",
       " 'led': 76353,\n",
       " 'having': 75929,\n",
       " 'court': 75693,\n",
       " 'himself': 75667,\n",
       " 'education': 75546,\n",
       " 'california': 75501,\n",
       " 'term': 75345,\n",
       " 'union': 75321,\n",
       " 'current': 75305,\n",
       " 'modern': 75031,\n",
       " 'free': 74961,\n",
       " 'society': 74938,\n",
       " 'next': 74789,\n",
       " '17': 74557,\n",
       " '1995': 74549,\n",
       " 'san': 74461,\n",
       " 'star': 74413,\n",
       " 'support': 74403,\n",
       " 'control': 74250,\n",
       " 'record': 74216,\n",
       " 'division': 74063,\n",
       " 'track': 74046,\n",
       " 'council': 74044,\n",
       " 'median': 73879,\n",
       " 'good': 73865,\n",
       " 'women': 73797,\n",
       " 'families': 73618,\n",
       " 'how': 73445,\n",
       " 'similar': 73387,\n",
       " 'field': 73336,\n",
       " '1991': 72606,\n",
       " 'considered': 72561,\n",
       " 'f': 72502,\n",
       " 'full': 72355,\n",
       " 'northern': 72265,\n",
       " 'married': 72034,\n",
       " 'special': 71771,\n",
       " 'others': 71531,\n",
       " '1994': 71434,\n",
       " 'went': 71338,\n",
       " 'science': 71248,\n",
       " 'period': 71189,\n",
       " 'role': 71071,\n",
       " 'run': 70952,\n",
       " 'program': 70929,\n",
       " 'level': 70884,\n",
       " 'press': 70746,\n",
       " 'total': 70712,\n",
       " 'produced': 70424,\n",
       " 'region': 70229,\n",
       " 'france': 70132,\n",
       " 'census': 70079,\n",
       " 'research': 70054,\n",
       " 'business': 70007,\n",
       " 'human': 69988,\n",
       " 'included': 69819,\n",
       " 'received': 69692,\n",
       " 'size': 69665,\n",
       " 'co': 69554,\n",
       " 'award': 69538,\n",
       " 'famous': 69526,\n",
       " 'australia': 69426,\n",
       " 'does': 69405,\n",
       " 'must': 69294,\n",
       " 'records': 69051,\n",
       " 'open': 68510,\n",
       " 'minister': 68367,\n",
       " 'office': 68282,\n",
       " '21': 68269,\n",
       " 'important': 68077,\n",
       " 'should': 68012,\n",
       " '19': 67975,\n",
       " 'body': 67966,\n",
       " 'founded': 67843,\n",
       " '1993': 67825,\n",
       " 'seen': 67705,\n",
       " 'royal': 67616,\n",
       " 'go': 67544,\n",
       " 'production': 67510,\n",
       " 'get': 67347,\n",
       " '1992': 66787,\n",
       " 'six': 66748,\n",
       " 'robert': 66698,\n",
       " 'japanese': 66596,\n",
       " 'moved': 66402,\n",
       " 'space': 66389,\n",
       " '22': 66374,\n",
       " 'lost': 66103,\n",
       " 'association': 66081,\n",
       " 'news': 65991,\n",
       " 'light': 65973,\n",
       " 'video': 65918,\n",
       " 'books': 65616,\n",
       " 'lake': 65471,\n",
       " 'days': 65451,\n",
       " 'originally': 65451,\n",
       " 'w': 65371,\n",
       " 'case': 64958,\n",
       " 'today': 64886,\n",
       " 'started': 64859,\n",
       " 'upon': 64795,\n",
       " 'southern': 64674,\n",
       " 'race': 64457,\n",
       " '=': 64273,\n",
       " 'further': 64209,\n",
       " 'india': 64017,\n",
       " 'design': 63904,\n",
       " 'paul': 63902,\n",
       " 'director': 63897,\n",
       " 'article': 63878,\n",
       " 'per': 63813,\n",
       " 'social': 63799,\n",
       " 'election': 63762,\n",
       " 'v': 63752,\n",
       " 'n': 63684,\n",
       " 'com': 63682,\n",
       " 'european': 63602,\n",
       " 'established': 63461,\n",
       " '23': 63308,\n",
       " 'males': 63187,\n",
       " 'project': 63128,\n",
       " 'available': 63088,\n",
       " 'al': 63081,\n",
       " 'making': 63048,\n",
       " 'fire': 62888,\n",
       " '1990': 62615,\n",
       " '65': 62492,\n",
       " 'night': 62469,\n",
       " 'services': 62246,\n",
       " 'females': 62227,\n",
       " 'forces': 62225,\n",
       " 're': 62171,\n",
       " 'h': 61818,\n",
       " 'hall': 61316,\n",
       " 'movie': 61315,\n",
       " 'me': 60965,\n",
       " 'canadian': 60830,\n",
       " 'sometimes': 60657,\n",
       " 'michael': 60532,\n",
       " 'charles': 60487,\n",
       " 'less': 60292,\n",
       " 'japan': 60259,\n",
       " 'events': 60072,\n",
       " 'schools': 59900,\n",
       " '26': 59787,\n",
       " 'half': 59757,\n",
       " 'route': 59745,\n",
       " 'style': 59741,\n",
       " 'appeared': 59730,\n",
       " 'older': 59486,\n",
       " 'type': 59216,\n",
       " 'formed': 58897,\n",
       " 'away': 58730,\n",
       " 'thus': 58444,\n",
       " 'position': 58284,\n",
       " '28': 58270,\n",
       " 'eventually': 58155,\n",
       " 'release': 57814,\n",
       " 'million': 57779,\n",
       " 'link': 57734,\n",
       " 'department': 57730,\n",
       " 'dr': 57712,\n",
       " 'areas': 57679,\n",
       " 'page': 57674,\n",
       " 'kingdom': 57558,\n",
       " 'cup': 57410,\n",
       " 'real': 57409,\n",
       " 'big': 57310,\n",
       " 'germany': 57219,\n",
       " 'sea': 57189,\n",
       " 'households': 57121,\n",
       " '27': 56996,\n",
       " 'playing': 56972,\n",
       " 'songs': 56949,\n",
       " 'post': 56858,\n",
       " 'species': 56754,\n",
       " 'green': 56745,\n",
       " 'thomas': 56673,\n",
       " 'k': 56522,\n",
       " 'europe': 56502,\n",
       " 'elected': 56301,\n",
       " 'your': 56220,\n",
       " 'middle': 56108,\n",
       " 'network': 55990,\n",
       " 'result': 55958,\n",
       " 'mother': 55838,\n",
       " 'developed': 55503,\n",
       " 'blue': 55207,\n",
       " 'lead': 55144,\n",
       " 'taken': 55078,\n",
       " 'board': 55064,\n",
       " 'systems': 54991,\n",
       " 'returned': 54923,\n",
       " 'washington': 54878,\n",
       " 'rather': 54877,\n",
       " '1989': 54792,\n",
       " 'fact': 54638,\n",
       " '2007': 54611,\n",
       " 'km²': 54596,\n",
       " 'working': 54265,\n",
       " 'god': 54115,\n",
       " 'either': 53918,\n",
       " 'continued': 53585,\n",
       " 'australian': 53553,\n",
       " 'features': 53547,\n",
       " 'almost': 53529,\n",
       " '1981': 53521,\n",
       " 'peter': 53396,\n",
       " 'below': 53388,\n",
       " 'earth': 53383,\n",
       " 'police': 53373,\n",
       " 'centre': 53348,\n",
       " 'attack': 53263,\n",
       " 'female': 53229,\n",
       " 'throughout': 53147,\n",
       " 'chief': 52975,\n",
       " 'wife': 52868,\n",
       " 'soon': 52812,\n",
       " 'car': 52772,\n",
       " '29': 52767,\n",
       " 'largest': 52697,\n",
       " 'help': 52623,\n",
       " 'players': 52613,\n",
       " 'eastern': 52596,\n",
       " 'come': 52581,\n",
       " 'china': 52516,\n",
       " 'brother': 52140,\n",
       " 'range': 52086,\n",
       " '/': 51885,\n",
       " 'characters': 51820,\n",
       " 'process': 51565,\n",
       " '1988': 51434,\n",
       " 'addition': 51398,\n",
       " 'far': 51377,\n",
       " 'killed': 51330,\n",
       " '1987': 51308,\n",
       " 'native': 51262,\n",
       " 'railway': 51214,\n",
       " 'airport': 51166,\n",
       " 'model': 50974,\n",
       " 'township': 50877,\n",
       " 'includes': 50840,\n",
       " 'round': 50815,\n",
       " 'summer': 50814,\n",
       " 'magazine': 50810,\n",
       " '50': 50794,\n",
       " 'instead': 50781,\n",
       " 'above': 50695,\n",
       " 'richard': 50679,\n",
       " 'km': 50653,\n",
       " 'worked': 50623,\n",
       " 'groups': 50616,\n",
       " 'return': 50575,\n",
       " 'museum': 50534,\n",
       " 'able': 50482,\n",
       " 'data': 50390,\n",
       " 'word': 50385,\n",
       " 'recorded': 50364,\n",
       " 'generally': 50351,\n",
       " 'http': 50347,\n",
       " 'lord': 50138,\n",
       " 'hand': 50056,\n",
       " 'standard': 50009,\n",
       " 'computer': 49999,\n",
       " 'person': 49943,\n",
       " 'don': 49907,\n",
       " 'itself': 49873,\n",
       " 'leader': 49870,\n",
       " 'technology': 49661,\n",
       " 'joined': 49659,\n",
       " 'african': 49617,\n",
       " 'despite': 49591,\n",
       " 'here': 49456,\n",
       " 'guitar': 49315,\n",
       " 'means': 49246,\n",
       " 'too': 49245,\n",
       " 'independent': 49233,\n",
       " 'till': 49116,\n",
       " 'henry': 49105,\n",
       " '1986': 49023,\n",
       " 'indian': 49005,\n",
       " 'possible': 48980,\n",
       " 'training': 48945,\n",
       " 'especially': 48688,\n",
       " 'low': 48686,\n",
       " 'units': 48676,\n",
       " 'action': 48566,\n",
       " 'christian': 48565,\n",
       " 'civil': 48431,\n",
       " 'movement': 48422,\n",
       " 'republic': 48359,\n",
       " '1980': 48138,\n",
       " '31': 48130,\n",
       " 'roman': 48065,\n",
       " 'hill': 47934,\n",
       " 'province': 47916,\n",
       " 'points': 47821,\n",
       " 'opened': 47718,\n",
       " 'close': 47649,\n",
       " 'across': 47555,\n",
       " 'wrote': 47510,\n",
       " 'professional': 47479,\n",
       " 'miles': 47462,\n",
       " 'ireland': 47411,\n",
       " 'ship': 47402,\n",
       " 'actor': 47329,\n",
       " 'chinese': 47195,\n",
       " 'championship': 47172,\n",
       " '1985': 47112,\n",
       " '1984': 47050,\n",
       " 'hit': 46922,\n",
       " 'find': 46912,\n",
       " 'arts': 46867,\n",
       " 'change': 46867,\n",
       " 'ever': 46822,\n",
       " 'seven': 46815,\n",
       " 'density': 46664,\n",
       " 'future': 46656,\n",
       " 'gold': 46627,\n",
       " 'aircraft': 46624,\n",
       " 'our': 46622,\n",
       " 'mr': 46615,\n",
       " 'theory': 46539,\n",
       " 'health': 46455,\n",
       " 'sound': 46382,\n",
       " 'culture': 46352,\n",
       " 'institute': 46327,\n",
       " 'grand': 46169,\n",
       " 'related': 46063,\n",
       " 'front': 45980,\n",
       " '1971': 45977,\n",
       " '40': 45841,\n",
       " 'valley': 45793,\n",
       " 'parts': 45774,\n",
       " 'mark': 45745,\n",
       " 'base': 45698,\n",
       " 'shows': 45660,\n",
       " 'market': 45550,\n",
       " 'daughter': 45544,\n",
       " 'media': 45512,\n",
       " 'designed': 45354,\n",
       " 'author': 45142,\n",
       " 'coast': 44960,\n",
       " 'always': 44798,\n",
       " 'featured': 44772,\n",
       " 'novel': 44741,\n",
       " 'stage': 44718,\n",
       " 'rights': 44689,\n",
       " 'shift': 44633,\n",
       " 'capital': 44613,\n",
       " 'prince': 44529,\n",
       " 'student': 44520,\n",
       " 'spanish': 44438,\n",
       " 'past': 44424,\n",
       " '1983': 44418,\n",
       " 'least': 44386,\n",
       " 'bridge': 44310,\n",
       " 'bay': 44306,\n",
       " 'countries': 44299,\n",
       " 'texas': 44282,\n",
       " '1979': 44176,\n",
       " 'cross': 44164,\n",
       " 'whose': 44143,\n",
       " 'races': 44051,\n",
       " 'organization': 44050,\n",
       " 'sports': 43941,\n",
       " 'leading': 43828,\n",
       " 'success': 43811,\n",
       " 'sir': 43793,\n",
       " '1982': 43738,\n",
       " 'private': 43686,\n",
       " 'put': 43637,\n",
       " 'construction': 43507,\n",
       " 'performance': 43477,\n",
       " 'energy': 43379,\n",
       " 'sold': 43303,\n",
       " 'source': 43294,\n",
       " 'section': 43241,\n",
       " 'uses': 43138,\n",
       " 'smith': 43042,\n",
       " 'study': 42911,\n",
       " 'russian': 42859,\n",
       " 'saint': 42806,\n",
       " 'household': 42780,\n",
       " 'strong': 42748,\n",
       " 'awards': 42740,\n",
       " 'ground': 42596,\n",
       " 'outside': 42596,\n",
       " 'traditional': 42478,\n",
       " 'self': 42436,\n",
       " 'channel': 42303,\n",
       " 'tour': 42250,\n",
       " 'empire': 42118,\n",
       " '45': 42074,\n",
       " 'federal': 42060,\n",
       " 'natural': 41987,\n",
       " 'governor': 41913,\n",
       " 'primary': 41758,\n",
       " 'studies': 41555,\n",
       " 'successful': 41492,\n",
       " 'lower': 41458,\n",
       " 'beginning': 41453,\n",
       " 'performed': 41367,\n",
       " 'followed': 41363,\n",
       " 'months': 41325,\n",
       " 'sent': 41189,\n",
       " 'los': 41088,\n",
       " 'writer': 41059,\n",
       " 'bill': 41043,\n",
       " '//www': 41026,\n",
       " 'notes': 41019,\n",
       " 'reference': 40968,\n",
       " 'africa': 40927,\n",
       " 'queen': 40860,\n",
       " 'recent': 40830,\n",
       " 'films': 40828,\n",
       " 'prime': 40745,\n",
       " 'start': 40743,\n",
       " 'industry': 40734,\n",
       " 'child': 40704,\n",
       " 'appears': 40644,\n",
       " 'money': 40624,\n",
       " 'certain': 40620,\n",
       " 'notable': 40612,\n",
       " '1970': 40545,\n",
       " 'brown': 40485,\n",
       " 'trade': 40472,\n",
       " 'ten': 40461,\n",
       " 'woman': 40428,\n",
       " 'involved': 40427,\n",
       " 'win': 40296,\n",
       " 'value': 40292,\n",
       " 'chicago': 40285,\n",
       " 'committee': 40267,\n",
       " 'vocals': 40225,\n",
       " 'limited': 40219,\n",
       " 'higher': 40189,\n",
       " 'finally': 40188,\n",
       " 'parliament': 40126,\n",
       " 'behind': 40093,\n",
       " 'food': 40076,\n",
       " 'personal': 40041,\n",
       " 'bank': 40001,\n",
       " 'italian': 39987,\n",
       " 'event': 39956,\n",
       " 'historical': 39866,\n",
       " 'library': 39825,\n",
       " 'academy': 39768,\n",
       " 'mid': 39736,\n",
       " 'brought': 39726,\n",
       " '1978': 39716,\n",
       " 'professor': 39713,\n",
       " 'complete': 39691,\n",
       " 'teams': 39684,\n",
       " 'fontsize': 39667,\n",
       " 'highway': 39650,\n",
       " 'management': 39526,\n",
       " 'navy': 39381,\n",
       " 'emperor': 39296,\n",
       " 'edition': 39294,\n",
       " 'catholic': 39286,\n",
       " '1976': 39133,\n",
       " 'introduced': 39094,\n",
       " '1975': 39079,\n",
       " 'master': 38895,\n",
       " 'singer': 38882,\n",
       " 'van': 38876,\n",
       " '1977': 38840,\n",
       " '1974': 38814,\n",
       " 'husband': 38790,\n",
       " 'course': 38762,\n",
       " 'appointed': 38674,\n",
       " 'interest': 38642,\n",
       " 'added': 38610,\n",
       " 'saw': 38593,\n",
       " 'gave': 38563,\n",
       " 'unit': 38545,\n",
       " 'names': 38528,\n",
       " 'actually': 38438,\n",
       " 'date': 38370,\n",
       " 'takes': 38367,\n",
       " 'paris': 38311,\n",
       " 'mary': 38278,\n",
       " 'greek': 38199,\n",
       " 'web': 38155,\n",
       " 'campaign': 38060,\n",
       " 'give': 38047,\n",
       " 'medical': 37956,\n",
       " 'changed': 37954,\n",
       " 'running': 37926,\n",
       " 'recently': 37904,\n",
       " 'collection': 37899,\n",
       " '1st': 37895,\n",
       " 'mountain': 37857,\n",
       " 'results': 37851,\n",
       " 'mission': 37844,\n",
       " '1972': 37832,\n",
       " 'remained': 37815,\n",
       " 'themselves': 37760,\n",
       " 'provide': 37754,\n",
       " 'replaced': 37746,\n",
       " 'musical': 37631,\n",
       " 'nature': 37614,\n",
       " 'got': 37603,\n",
       " 'degree': 37579,\n",
       " 'heart': 37549,\n",
       " 'code': 37527,\n",
       " 'operations': 37526,\n",
       " 'ancient': 37490,\n",
       " 'anti': 37489,\n",
       " 'speed': 37435,\n",
       " 'captain': 37422,\n",
       " 'religious': 37369,\n",
       " 'operation': 37346,\n",
       " 'foreign': 37328,\n",
       " 'friends': 37314,\n",
       " 'biography': 37238,\n",
       " 'better': 37206,\n",
       " '1973': 37154,\n",
       " 'dead': 37129,\n",
       " 'move': 37053,\n",
       " 'thought': 37034,\n",
       " 'alone': 36961,\n",
       " 'festival': 36892,\n",
       " 'soviet': 36837,\n",
       " 'command': 36823,\n",
       " 'engine': 36810,\n",
       " 'taking': 36757,\n",
       " 'view': 36723,\n",
       " 'runs': 36643,\n",
       " 'martin': 36611,\n",
       " 'mi²': 36594,\n",
       " 'previous': 36499,\n",
       " 'cities': 36352,\n",
       " 'economic': 36310,\n",
       " 'turn': 36280,\n",
       " 'pacific': 36269,\n",
       " 'location': 36256,\n",
       " 'test': 36191,\n",
       " '1961': 36171,\n",
       " 'online': 36140,\n",
       " 'contains': 36124,\n",
       " 'jack': 36101,\n",
       " 'decided': 36044,\n",
       " 'writing': 36012,\n",
       " 'going': 35975,\n",
       " 'words': 35973,\n",
       " 'theatre': 35918,\n",
       " 'square': 35880,\n",
       " 'true': 35865,\n",
       " 'irish': 35852,\n",
       " 'fall': 35805,\n",
       " 'wide': 35790,\n",
       " 'artist': 35786,\n",
       " 'virginia': 35775,\n",
       " 'described': 35759,\n",
       " 'dark': 35752,\n",
       " 'room': 35734,\n",
       " '1968': 35703,\n",
       " 'makes': 35613,\n",
       " 'match': 35592,\n",
       " 'owned': 35571,\n",
       " 'yet': 35551,\n",
       " 'individuals': 35535,\n",
       " 'active': 35498,\n",
       " 'particularly': 35491,\n",
       " 'particular': 35481,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count[0] = (word_count[0][0], word_count[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordcount.json', 'w') as fp:\n",
    "    json.dump(word_count, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataloc.txt', 'w') as f:\n",
    "    for item in data:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[711,\n",
       " 27651,\n",
       " 1,\n",
       " 13,\n",
       " 293,\n",
       " 216,\n",
       " 4,\n",
       " 1,\n",
       " 9441,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 261,\n",
       " 501,\n",
       " 4,\n",
       " 1,\n",
       " 4903,\n",
       " 12,\n",
       " 1,\n",
       " 16,\n",
       " 31,\n",
       " 1,\n",
       " 246,\n",
       " 3025,\n",
       " 3,\n",
       " 2,\n",
       " 70,\n",
       " 332,\n",
       " 5,\n",
       " 137,\n",
       " 27651,\n",
       " 4,\n",
       " 1,\n",
       " 4608,\n",
       " 5,\n",
       " 5529,\n",
       " 6,\n",
       " 2643,\n",
       " 5,\n",
       " 4210,\n",
       " 4,\n",
       " 1,\n",
       " 25,\n",
       " 16,\n",
       " 2747,\n",
       " 29,\n",
       " 14116,\n",
       " 6,\n",
       " 2033,\n",
       " 264,\n",
       " 4,\n",
       " 1,\n",
       " 1528,\n",
       " 4,\n",
       " 1,\n",
       " 5146,\n",
       " 7,\n",
       " 8372,\n",
       " 3,\n",
       " 1,\n",
       " 144,\n",
       " 11,\n",
       " 2,\n",
       " 214,\n",
       " 4,\n",
       " 1,\n",
       " 25,\n",
       " 16053,\n",
       " 18,\n",
       " 69,\n",
       " 75,\n",
       " 22,\n",
       " 2,\n",
       " 1528,\n",
       " 2555,\n",
       " 8,\n",
       " 1,\n",
       " 44,\n",
       " 30,\n",
       " 13514,\n",
       " 33,\n",
       " 2075,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 59,\n",
       " 4,\n",
       " 1,\n",
       " 22,\n",
       " 30,\n",
       " 357,\n",
       " 17,\n",
       " 21,\n",
       " 268,\n",
       " 7,\n",
       " 5116,\n",
       " 4,\n",
       " 1,\n",
       " 25,\n",
       " 5365,\n",
       " 9,\n",
       " 242,\n",
       " 1862,\n",
       " 7,\n",
       " 11159,\n",
       " 4,\n",
       " 1,\n",
       " 25,\n",
       " 908,\n",
       " 436,\n",
       " 74,\n",
       " 8476,\n",
       " 11,\n",
       " 1672,\n",
       " 813,\n",
       " 3,\n",
       " 1,\n",
       " 25,\n",
       " 41,\n",
       " 366,\n",
       " 2047,\n",
       " 24,\n",
       " 2,\n",
       " 6855,\n",
       " 197,\n",
       " 5,\n",
       " 3233,\n",
       " 6,\n",
       " 5342,\n",
       " 47,\n",
       " 433,\n",
       " 2,\n",
       " 9104,\n",
       " 203,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 2109,\n",
       " 11,\n",
       " 36,\n",
       " 25,\n",
       " 12911,\n",
       " 30,\n",
       " 4565,\n",
       " 11,\n",
       " 2,\n",
       " 119,\n",
       " 10,\n",
       " 2239,\n",
       " 6,\n",
       " 2384,\n",
       " 607,\n",
       " 5,\n",
       " 3909,\n",
       " 5,\n",
       " 7353,\n",
       " 8,\n",
       " 1,\n",
       " 44,\n",
       " 325,\n",
       " 85,\n",
       " 114,\n",
       " 7,\n",
       " 1354,\n",
       " 436,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 25,\n",
       " 16,\n",
       " 4,\n",
       " 1,\n",
       " 113,\n",
       " 4,\n",
       " 1,\n",
       " 31,\n",
       " 997,\n",
       " 6307,\n",
       " 5,\n",
       " 78,\n",
       " 346,\n",
       " 3059,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 998,\n",
       " 5,\n",
       " 26,\n",
       " 36,\n",
       " 1275,\n",
       " 7,\n",
       " 2,\n",
       " 10346,\n",
       " 5,\n",
       " 2,\n",
       " 4007,\n",
       " 859,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 25,\n",
       " 16,\n",
       " 33400,\n",
       " 2828,\n",
       " 11,\n",
       " 2,\n",
       " 367,\n",
       " 3050,\n",
       " 5,\n",
       " 2,\n",
       " 25384,\n",
       " 3,\n",
       " 1,\n",
       " 27651,\n",
       " 17,\n",
       " 21,\n",
       " 2835,\n",
       " 2075,\n",
       " 173,\n",
       " 16,\n",
       " 8134,\n",
       " 7,\n",
       " 37528,\n",
       " 24,\n",
       " 2,\n",
       " 235,\n",
       " 3560,\n",
       " 5,\n",
       " 2,\n",
       " 9104,\n",
       " 203,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3318,\n",
       " 1070,\n",
       " 4,\n",
       " 1,\n",
       " 99,\n",
       " 30,\n",
       " 1070,\n",
       " 5,\n",
       " 1372,\n",
       " 17,\n",
       " 21,\n",
       " 19548,\n",
       " 3979,\n",
       " 1762,\n",
       " 3,\n",
       " 1,\n",
       " 30,\n",
       " 43,\n",
       " 235,\n",
       " 173,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 961,\n",
       " 5,\n",
       " 2,\n",
       " 101,\n",
       " 5,\n",
       " 612,\n",
       " 79,\n",
       " 2,\n",
       " 615,\n",
       " 2845,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 481,\n",
       " 7,\n",
       " 7002,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 16,\n",
       " 836,\n",
       " 1308,\n",
       " 75,\n",
       " 108,\n",
       " 23,\n",
       " 2,\n",
       " 3431,\n",
       " 126,\n",
       " 5,\n",
       " 360,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 6087,\n",
       " 10,\n",
       " 5976,\n",
       " 581,\n",
       " 2,\n",
       " 1774,\n",
       " 11,\n",
       " 2,\n",
       " 1211,\n",
       " 5,\n",
       " 612,\n",
       " 7,\n",
       " 2,\n",
       " 3658,\n",
       " 4,\n",
       " 1,\n",
       " 3162,\n",
       " 6,\n",
       " 3083,\n",
       " 2261,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 103,\n",
       " 32,\n",
       " 2,\n",
       " 116,\n",
       " 425,\n",
       " 22,\n",
       " 36,\n",
       " 27651,\n",
       " 17,\n",
       " 21,\n",
       " 1557,\n",
       " 13463,\n",
       " 3,\n",
       " 1,\n",
       " 48,\n",
       " 325,\n",
       " 9,\n",
       " 220,\n",
       " 7,\n",
       " 246,\n",
       " 1211,\n",
       " 36,\n",
       " 16,\n",
       " 42,\n",
       " 5261,\n",
       " 6038,\n",
       " 171,\n",
       " 2,\n",
       " 1526,\n",
       " 226,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 1242,\n",
       " 5,\n",
       " 20568,\n",
       " 843,\n",
       " 11,\n",
       " 30,\n",
       " 615,\n",
       " 2845,\n",
       " 16,\n",
       " 345,\n",
       " 7,\n",
       " 4392,\n",
       " 8,\n",
       " 1,\n",
       " 103,\n",
       " 3937,\n",
       " 6,\n",
       " 2584,\n",
       " 2587,\n",
       " 1217,\n",
       " 53,\n",
       " 5,\n",
       " 27651,\n",
       " 17,\n",
       " 21,\n",
       " 322,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 6851,\n",
       " 874,\n",
       " 905,\n",
       " 7,\n",
       " 30,\n",
       " 153,\n",
       " 16,\n",
       " 2,\n",
       " 38957,\n",
       " 36,\n",
       " 0,\n",
       " 88,\n",
       " 7,\n",
       " 2,\n",
       " 1565,\n",
       " 5,\n",
       " 30,\n",
       " 286,\n",
       " 4,\n",
       " 1,\n",
       " 40,\n",
       " 51,\n",
       " 224,\n",
       " 3,\n",
       " 1,\n",
       " 30,\n",
       " 4725,\n",
       " 332,\n",
       " 4,\n",
       " 1,\n",
       " 1651,\n",
       " 711,\n",
       " 27651,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 9,\n",
       " 3,\n",
       " 565,\n",
       " 3,\n",
       " 565,\n",
       " 3,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 22705,\n",
       " 17,\n",
       " 21,\n",
       " 7,\n",
       " 32727,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 23,\n",
       " 2,\n",
       " 6779,\n",
       " 5,\n",
       " 30,\n",
       " 10063,\n",
       " 9,\n",
       " 230,\n",
       " 5,\n",
       " 2,\n",
       " 66,\n",
       " 6855,\n",
       " 5143,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 343,\n",
       " 7,\n",
       " 6863,\n",
       " 29,\n",
       " 2,\n",
       " 115,\n",
       " 5,\n",
       " 1700,\n",
       " 10,\n",
       " 56,\n",
       " 3,\n",
       " 1,\n",
       " 8143,\n",
       " 75,\n",
       " 108,\n",
       " 4,\n",
       " 1,\n",
       " 30,\n",
       " 148,\n",
       " 332,\n",
       " 4,\n",
       " 1,\n",
       " 711,\n",
       " 39428,\n",
       " 27651,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 1322,\n",
       " 257,\n",
       " 154,\n",
       " 30,\n",
       " 659,\n",
       " 29,\n",
       " 2,\n",
       " 192,\n",
       " 10666,\n",
       " 5,\n",
       " 223,\n",
       " 1029,\n",
       " 49,\n",
       " 60,\n",
       " 9,\n",
       " 235,\n",
       " 322,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 15332,\n",
       " 268,\n",
       " 6,\n",
       " 124,\n",
       " 7325,\n",
       " 5,\n",
       " 103,\n",
       " 406,\n",
       " 330,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 521,\n",
       " 5,\n",
       " 40,\n",
       " 5,\n",
       " 112,\n",
       " 24,\n",
       " 2,\n",
       " 66,\n",
       " 346,\n",
       " 3146,\n",
       " 5,\n",
       " 2,\n",
       " 115,\n",
       " 4,\n",
       " 1,\n",
       " 49,\n",
       " 106,\n",
       " 27651,\n",
       " 17,\n",
       " 21,\n",
       " 150,\n",
       " 0,\n",
       " 950,\n",
       " 93,\n",
       " 104,\n",
       " 167,\n",
       " 52,\n",
       " 6667,\n",
       " 5,\n",
       " 30,\n",
       " 153,\n",
       " 3,\n",
       " 1,\n",
       " 25,\n",
       " 2988,\n",
       " 649,\n",
       " 4,\n",
       " 1,\n",
       " 771,\n",
       " 6,\n",
       " 1930,\n",
       " 23,\n",
       " 78,\n",
       " 75,\n",
       " 3,\n",
       " 7,\n",
       " 6478,\n",
       " 27651,\n",
       " 345,\n",
       " 2,\n",
       " 1097,\n",
       " 7,\n",
       " 7511,\n",
       " 6,\n",
       " 4215,\n",
       " 5,\n",
       " 1651,\n",
       " 711,\n",
       " 27651,\n",
       " 4,\n",
       " 1,\n",
       " 24,\n",
       " 9,\n",
       " 5760,\n",
       " 5,\n",
       " 30,\n",
       " 153,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 5315,\n",
       " 9,\n",
       " 2901,\n",
       " 5,\n",
       " 2075,\n",
       " 4594,\n",
       " 6,\n",
       " 662,\n",
       " 27,\n",
       " 2,\n",
       " 1211,\n",
       " 5,\n",
       " 612,\n",
       " 16,\n",
       " 345,\n",
       " 3,\n",
       " 1,\n",
       " 27651,\n",
       " 16,\n",
       " 9,\n",
       " 1687,\n",
       " 5,\n",
       " 2,\n",
       " 509,\n",
       " 444,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 10590,\n",
       " 5,\n",
       " 2,\n",
       " 195,\n",
       " 686,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 3907,\n",
       " 78,\n",
       " 52,\n",
       " 3622,\n",
       " 14512,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 5564,\n",
       " 25,\n",
       " 489,\n",
       " 2,\n",
       " 751,\n",
       " 1065,\n",
       " 18,\n",
       " 126,\n",
       " 4,\n",
       " 1,\n",
       " 506,\n",
       " 23,\n",
       " 397,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 615,\n",
       " 2845,\n",
       " 15,\n",
       " 988,\n",
       " 23,\n",
       " 27651,\n",
       " 436,\n",
       " 20,\n",
       " 9,\n",
       " 128,\n",
       " 5,\n",
       " 878,\n",
       " 45310,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 3997,\n",
       " 3194,\n",
       " 5,\n",
       " 2,\n",
       " 648,\n",
       " 3825,\n",
       " 26,\n",
       " 68,\n",
       " 905,\n",
       " 9,\n",
       " 4727,\n",
       " 26072,\n",
       " 79,\n",
       " 2,\n",
       " 474,\n",
       " 27,\n",
       " 2,\n",
       " 2323,\n",
       " 11,\n",
       " 2,\n",
       " 3658,\n",
       " 226,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 173,\n",
       " 1429,\n",
       " 5,\n",
       " 1308,\n",
       " 198,\n",
       " 5066,\n",
       " 4,\n",
       " 1,\n",
       " 176,\n",
       " 5,\n",
       " 36,\n",
       " 15,\n",
       " 9,\n",
       " 885,\n",
       " 9325,\n",
       " 7,\n",
       " 699,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 126,\n",
       " 5,\n",
       " 483,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1058,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1208,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 601,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 916,\n",
       " 6,\n",
       " 0,\n",
       " 12973,\n",
       " 4,\n",
       " 1,\n",
       " 40308,\n",
       " 7,\n",
       " 3103,\n",
       " 6,\n",
       " 181,\n",
       " 1049,\n",
       " 4,\n",
       " 1,\n",
       " 15,\n",
       " 2,\n",
       " 1159,\n",
       " 5,\n",
       " 349,\n",
       " 1244,\n",
       " 5066,\n",
       " 3,\n",
       " 1,\n",
       " 470,\n",
       " 1411,\n",
       " 24,\n",
       " 2,\n",
       " 235,\n",
       " 9981,\n",
       " 637,\n",
       " 5,\n",
       " 2807,\n",
       " 444,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 2,\n",
       " 410,\n",
       " 5,\n",
       " 2,\n",
       " 10138,\n",
       " 184,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 8032,\n",
       " 184,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 443,\n",
       " 367,\n",
       " 184,\n",
       " 5,\n",
       " 360,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 271,\n",
       " 1997,\n",
       " 8224,\n",
       " 2,\n",
       " 181,\n",
       " 101,\n",
       " 5,\n",
       " 444,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1613,\n",
       " 5,\n",
       " 3350,\n",
       " 4,\n",
       " 1,\n",
       " 11769,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1211,\n",
       " 7,\n",
       " 2,\n",
       " 615,\n",
       " 2845,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 238,\n",
       " 84,\n",
       " 37,\n",
       " 2171,\n",
       " 20,\n",
       " 9,\n",
       " 181,\n",
       " 961,\n",
       " 5,\n",
       " 168,\n",
       " 442,\n",
       " 126,\n",
       " 4,\n",
       " 1,\n",
       " 8905,\n",
       " 11,\n",
       " 2,\n",
       " 63,\n",
       " 3213,\n",
       " 1752,\n",
       " 5,\n",
       " 469,\n",
       " 1033,\n",
       " 5,\n",
       " 6921,\n",
       " 1553,\n",
       " 82,\n",
       " 7,\n",
       " 30,\n",
       " 2282,\n",
       " 425,\n",
       " 4,\n",
       " 1,\n",
       " 219,\n",
       " 27651,\n",
       " 17,\n",
       " 21,\n",
       " 296,\n",
       " 5133,\n",
       " 16,\n",
       " 11,\n",
       " 1601,\n",
       " 2,\n",
       " 173,\n",
       " 22,\n",
       " 2,\n",
       " 1788,\n",
       " 22,\n",
       " 36,\n",
       " 28,\n",
       " 41,\n",
       " 60,\n",
       " 3523,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3431,\n",
       " 126,\n",
       " 5,\n",
       " 360,\n",
       " 913,\n",
       " 74,\n",
       " 2,\n",
       " 1159,\n",
       " 29,\n",
       " 2,\n",
       " 347,\n",
       " 29,\n",
       " 36,\n",
       " 28,\n",
       " 41,\n",
       " 60,\n",
       " 2451,\n",
       " 7,\n",
       " 2,\n",
       " 961,\n",
       " 5,\n",
       " 2,\n",
       " 615,\n",
       " 2845,\n",
       " 4,\n",
       " 1,\n",
       " 17075,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 11331,\n",
       " 5,\n",
       " 711,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4553,\n",
       " 28,\n",
       " 291,\n",
       " 11,\n",
       " 2,\n",
       " 11331,\n",
       " 5,\n",
       " 397,\n",
       " 3,\n",
       " 1,\n",
       " 27651,\n",
       " 3249,\n",
       " 705,\n",
       " 18,\n",
       " 9,\n",
       " 4474,\n",
       " 1501,\n",
       " 4,\n",
       " 1,\n",
       " 36,\n",
       " 28,\n",
       " 15,\n",
       " 3556,\n",
       " 42,\n",
       " 11,\n",
       " 2664,\n",
       " 6,\n",
       " 11,\n",
       " 14523,\n",
       " 3,\n",
       " 1,\n",
       " 25,\n",
       " 16,\n",
       " 12744,\n",
       " 11,\n",
       " 37370,\n",
       " 2,\n",
       " 33020,\n",
       " 5,\n",
       " 442,\n",
       " 1354,\n",
       " 36,\n",
       " 3791,\n",
       " 11,\n",
       " 88,\n",
       " 11,\n",
       " 476,\n",
       " 199,\n",
       " 129,\n",
       " 2,\n",
       " 1192,\n",
       " 474,\n",
       " 5,\n",
       " 2,\n",
       " 2697,\n",
       " 5,\n",
       " 397,\n",
       " 8,\n",
       " 1,\n",
       " 3489,\n",
       " 4,\n",
       " 1,\n",
       " 25,\n",
       " 16,\n",
       " 3207,\n",
       " 5,\n",
       " 8213,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7668,\n",
       " 1070,\n",
       " 18,\n",
       " 6999,\n",
       " 974,\n",
       " 31,\n",
       " 542,\n",
       " 22,\n",
       " 2,\n",
       " 3431,\n",
       " 126,\n",
       " 4,\n",
       " 1,\n",
       " 416,\n",
       " 23,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 466,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 173,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
