{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"wiki_movie_plots.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step one: Convert plot to vectorized sequence of words.\n",
    "\n",
    "Step two: Set up LSTM to generate predictions.\n",
    "\n",
    "Step three: Interpret predictions.\n",
    "\n",
    "Ideas:\n",
    "- Predictions at every word (or sentence, or paragraph), see where they change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_to_consider = [\"drama\", \"comedy\", \"horror\", \"action\", \"thriller\", \"romance\", \"western\"]\n",
    "movies = movies[movies['Genre'].isin(genres_to_consider)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "      <td>5841</td>\n",
       "      <td>5964</td>\n",
       "      <td>5964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "      <td>4347</td>\n",
       "      <td>4379</td>\n",
       "      <td>4379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "      <td>1124</td>\n",
       "      <td>1167</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "      <td>1087</td>\n",
       "      <td>1098</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thriller</th>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>955</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "      <td>918</td>\n",
       "      <td>923</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>western</th>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>864</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Release Year  Title  Origin/Ethnicity  Director  Cast  Wiki Page  \\\n",
       "Genre                                                                        \n",
       "drama             5964   5964              5964      5964  5841       5964   \n",
       "comedy            4379   4379              4379      4379  4347       4379   \n",
       "horror            1167   1167              1167      1167  1124       1167   \n",
       "action            1098   1098              1098      1098  1087       1098   \n",
       "thriller           966    966               966       966   955        966   \n",
       "romance            923    923               923       923   918        923   \n",
       "western            865    865               865       865   864        865   \n",
       "\n",
       "          Plot  \n",
       "Genre           \n",
       "drama     5964  \n",
       "comedy    4379  \n",
       "horror    1167  \n",
       "action    1098  \n",
       "thriller   966  \n",
       "romance    923  \n",
       "western    865  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.groupby('Genre').count().sort_values(\"Title\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1907</td>\n",
       "      <td>How Brown Saw the Baseball Game</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/How_Brown_Saw_th...</td>\n",
       "      <td>Before heading out to a baseball game at a nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1907</td>\n",
       "      <td>Laughing Gas</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>Bertha Regustus, Edward Boulden</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Laughing_Gas_(fi...</td>\n",
       "      <td>The plot is that of a black woman going to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1908</td>\n",
       "      <td>The Adventures of Dollie</td>\n",
       "      <td>American</td>\n",
       "      <td>D. W. Griffith</td>\n",
       "      <td>Arthur V. Johnson, Linda Arvidson</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>On a beautiful summer day a father and mother ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Year                            Title Origin/Ethnicity  \\\n",
       "6           1903          The Great Train Robbery         American   \n",
       "7           1904                  The Suburbanite         American   \n",
       "14          1907  How Brown Saw the Baseball Game         American   \n",
       "15          1907                     Laughing Gas         American   \n",
       "16          1908         The Adventures of Dollie         American   \n",
       "\n",
       "                Director                               Cast    Genre  \\\n",
       "6        Edwin S. Porter                                NaN  western   \n",
       "7     Wallace McCutcheon                                NaN   comedy   \n",
       "14               Unknown                            Unknown   comedy   \n",
       "15  Edwin Stanton Porter    Bertha Regustus, Edward Boulden   comedy   \n",
       "16        D. W. Griffith  Arthur V. Johnson, Linda Arvidson    drama   \n",
       "\n",
       "                                            Wiki Page  \\\n",
       "6   https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7       https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "14  https://en.wikipedia.org/wiki/How_Brown_Saw_th...   \n",
       "15  https://en.wikipedia.org/wiki/Laughing_Gas_(fi...   \n",
       "16  https://en.wikipedia.org/wiki/The_Adventures_o...   \n",
       "\n",
       "                                                 Plot  \n",
       "6   The film opens with two bandits breaking into ...  \n",
       "7   The film is about a family who move to the sub...  \n",
       "14  Before heading out to a baseball game at a nea...  \n",
       "15  The plot is that of a black woman going to the...  \n",
       "16  On a beautiful summer day a father and mother ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.sample(frac=1) # Shuffles the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 600\n",
    "N_test = 200\n",
    "\n",
    "train = None\n",
    "test = None\n",
    "\n",
    "train = movies[movies['Genre'] == 'drama'][:N_train]\n",
    "test = movies[movies['Genre'] == 'drama'][N_train:]\n",
    "\n",
    "for genre in genres_to_consider[1:]:\n",
    "    tr = movies[movies['Genre'] == genre][:N_train]\n",
    "    te = movies[movies['Genre'] == genre][N_train:]\n",
    "    train = pd.concat([train, tr])\n",
    "    test = pd.concat([test, te])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>2006</td>\n",
       "      <td>Stephanie Daley</td>\n",
       "      <td>American</td>\n",
       "      <td>Hilary Brougher</td>\n",
       "      <td>Amber Tamblyn, Tilda Swinton, Timothy Hutton</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stephanie_Daley</td>\n",
       "      <td>Sixteen-year-old Stephanie Daley collapses in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17686</th>\n",
       "      <td>2000</td>\n",
       "      <td>Dish, TheThe Dish</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Rob Sitch</td>\n",
       "      <td>Sam Neill\\r\\nPatrick Warburton\\r\\nTom Long\\r\\n...</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Dish</td>\n",
       "      <td>The radio telescope at Parkes (Parkes Observat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>1958</td>\n",
       "      <td>The Missouri Traveler</td>\n",
       "      <td>American</td>\n",
       "      <td>Jerry Hopper</td>\n",
       "      <td>Brandon deWilde, Lee Marvin</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Missouri_Tra...</td>\n",
       "      <td>Brandon deWilde leads a cast lengthy in charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>1977</td>\n",
       "      <td>Bhumika</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>Shyam Benegal</td>\n",
       "      <td>Smita Patil, Naseeruddin Shah, Amrish Puri</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bhumika_(1977_film)</td>\n",
       "      <td>Bhumika tells the life story of an actress, Us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12575</th>\n",
       "      <td>1995</td>\n",
       "      <td>To the Limit</td>\n",
       "      <td>American</td>\n",
       "      <td>Raymond Martino</td>\n",
       "      <td>Anna Nicole Smith, Michael Nouri</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/To_the_Limit_(19...</td>\n",
       "      <td>Anna Nicole Smith plays Vickie Lynn, an ex-CIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                  Title Origin/Ethnicity         Director  \\\n",
       "15084          2006        Stephanie Daley         American  Hilary Brougher   \n",
       "17686          2000      Dish, TheThe Dish       Australian        Rob Sitch   \n",
       "7075           1958  The Missouri Traveler         American     Jerry Hopper   \n",
       "25002          1977                Bhumika        Bollywood    Shyam Benegal   \n",
       "12575          1995           To the Limit         American  Raymond Martino   \n",
       "\n",
       "                                                    Cast  Genre  \\\n",
       "15084       Amber Tamblyn, Tilda Swinton, Timothy Hutton  drama   \n",
       "17686  Sam Neill\\r\\nPatrick Warburton\\r\\nTom Long\\r\\n...  drama   \n",
       "7075                         Brandon deWilde, Lee Marvin  drama   \n",
       "25002         Smita Patil, Naseeruddin Shah, Amrish Puri  drama   \n",
       "12575                   Anna Nicole Smith, Michael Nouri  drama   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "15084      https://en.wikipedia.org/wiki/Stephanie_Daley   \n",
       "17686             https://en.wikipedia.org/wiki/The_Dish   \n",
       "7075   https://en.wikipedia.org/wiki/The_Missouri_Tra...   \n",
       "25002  https://en.wikipedia.org/wiki/Bhumika_(1977_film)   \n",
       "12575  https://en.wikipedia.org/wiki/To_the_Limit_(19...   \n",
       "\n",
       "                                                    Plot  \n",
       "15084  Sixteen-year-old Stephanie Daley collapses in ...  \n",
       "17686  The radio telescope at Parkes (Parkes Observat...  \n",
       "7075   Brandon deWilde leads a cast lengthy in charac...  \n",
       "25002  Bhumika tells the life story of an actress, Us...  \n",
       "12575  Anna Nicole Smith plays Vickie Lynn, an ex-CIA...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings Using Word2Vec on Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"(\" : \"( \",\n",
    "    \")\" : \" )\",\n",
    "    \"-\" : \" - \",\n",
    "    \",\" : \" ,\",\n",
    "    \"\\n\" : \"\",\n",
    "    \"\\r\" : \"\",\n",
    "    \"\\\"\" : \" \\\" \",\n",
    "    \"'\" : \" ' \",\n",
    "    \".\" : \" . \",\n",
    "    \"ENDOFARTICLE\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace various characters in a single pass over text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(d, text):\n",
    "    \n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, d.keys())))\n",
    "    \n",
    "    return regex.sub(lambda x: d[x.string[x.start():x.end()]], text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 164\n",
      "Files being used: 10\n"
     ]
    }
   ],
   "source": [
    "filename = \"wiki\"\n",
    "words = []\n",
    "\n",
    "files_in_directory = os.listdir(filename)\n",
    "print(\"Files in directory: \" + str(len(files_in_directory)))\n",
    "print(\"Files being used: \" + str(10))\n",
    "\n",
    "for file in files_in_directory[:10]:\n",
    "    f = open(filename + \"/\" + file, 'r', encoding = \"ISO-8859-1\")\n",
    "    f = f.read()\n",
    "    f = multiple_replace(d, f)\n",
    "    f = re.sub(\"<doc.{20,150}>\", \"\", f)\n",
    "    f = re.sub(\"</doc>\", \"\", f)\n",
    "    all_words = f.split(\" \")\n",
    "    for word in all_words:\n",
    "        words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(words, n_words):\n",
    "    word_count = [[\"UNK\", -1]]\n",
    "    word_count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    \n",
    "    d = {}\n",
    "    for w, _ in word_count:\n",
    "        d[w] = len(d)\n",
    "        \n",
    "    data = []\n",
    "    num_unks = 0\n",
    "    for w in words:\n",
    "        index = d.get(w, 0)\n",
    "        if index == 0:\n",
    "            num_unks += 1\n",
    "        data.append(index)\n",
    "            \n",
    "    word_count[0][1] = num_unks\n",
    "    \n",
    "    reversed_dictionary = dict(zip(d.values(), d.keys()))\n",
    "    \n",
    "    return data, word_count, d, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 100000 # Subject to change \n",
    "data, word_count, vocab_dictionary, reversed_dictionary = build_batch(words, n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def generate_batch(batch_size, data, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "    if data_index + span > len(data):\n",
    "        data_index = 0\n",
    "    buffer.extend(data[data_index:data_index + span])\n",
    "    data_index += span\n",
    "    for i in range(batch_size // num_skips):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        words_to_use = random.sample(context_words, num_skips)\n",
    "        for j, context_word in enumerate(words_to_use):\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "            \n",
    "        if data_index == len(data):\n",
    "            buffer.extend(data[0:span])\n",
    "            data_index = span\n",
    "        else:\n",
    "            buffer.append(data[data_index])\n",
    "            data_index += 1\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128\n",
    "skip_window = 1\n",
    "num_skips = 2\n",
    "num_sampled = 64\n",
    "\n",
    "valid_size = 16\n",
    "valid_window = 100\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.name_scope('inputs'):\n",
    "      train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "      train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "      valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    with tf.name_scope('embeddings'):\n",
    "        embeddings = tf.Variable(\n",
    "            tf.random_uniform([n_words, embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "    \n",
    "    with tf.name_scope(\"weights\"):\n",
    "        \n",
    "        nce_weights = tf.Variable(tf.truncated_normal([n_words, embedding_size],\n",
    "                                stddev=1.0 / math.sqrt(embedding_size)))\n",
    "        \n",
    "    with tf.name_scope('biases'):\n",
    "        \n",
    "        nce_biases = tf.Variable(tf.zeros([n_words]))\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "      loss = tf.reduce_mean(\n",
    "          tf.nn.nce_loss(\n",
    "              weights=nce_weights,\n",
    "              biases=nce_biases,\n",
    "              labels=train_labels,\n",
    "              inputs=embed,\n",
    "              num_sampled=num_sampled,\n",
    "              num_classes=n_words))\n",
    "    \n",
    "    tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    with tf.name_scope('optimizer'):\n",
    "      optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings,\n",
    "                                              valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "        valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model to obtain embeddings for each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step  0 :  267.1926574707031\n",
      "Average loss at step  2000 :  150.12939685058595\n",
      "Average loss at step  4000 :  87.6103204126358\n",
      "Average loss at step  6000 :  62.80463714456558\n",
      "Average loss at step  8000 :  49.22242328047752\n",
      "Average loss at step  10000 :  39.331454894900325\n",
      "Average loss at step  12000 :  36.64724566411972\n",
      "Average loss at step  14000 :  27.990575132846832\n",
      "Average loss at step  16000 :  23.667969947099685\n",
      "Average loss at step  18000 :  19.935047299623488\n",
      "Average loss at step  20000 :  17.869345844388008\n",
      "Average loss at step  22000 :  16.380260180354117\n",
      "Average loss at step  24000 :  13.991367206811905\n",
      "Average loss at step  26000 :  12.450434812963008\n",
      "Average loss at step  28000 :  12.40612879383564\n",
      "Average loss at step  30000 :  10.860905973792075\n",
      "Average loss at step  32000 :  10.349412953615188\n",
      "Average loss at step  34000 :  9.506500377058982\n",
      "Average loss at step  36000 :  9.001470514655113\n",
      "Average loss at step  38000 :  8.640172551155091\n",
      "Average loss at step  40000 :  8.35319882684946\n",
      "Average loss at step  42000 :  7.681345525979996\n",
      "Average loss at step  44000 :  7.36400529551506\n",
      "Average loss at step  46000 :  7.209201145350933\n",
      "Average loss at step  48000 :  6.979794981867075\n",
      "Average loss at step  50000 :  6.642515088200569\n",
      "Average loss at step  52000 :  6.797404655098915\n",
      "Average loss at step  54000 :  6.510522119402886\n",
      "Average loss at step  56000 :  6.333575985908508\n",
      "Average loss at step  58000 :  6.221490243792534\n",
      "Average loss at step  60000 :  6.286540151178837\n",
      "Average loss at step  62000 :  6.5530848662853245\n",
      "Average loss at step  64000 :  6.832577831149101\n",
      "Average loss at step  66000 :  22.47649487346411\n",
      "Average loss at step  68000 :  9.521313700512051\n",
      "Average loss at step  70000 :  6.603622434228659\n",
      "Average loss at step  72000 :  6.139623487949371\n",
      "Average loss at step  74000 :  6.171872787117958\n",
      "Average loss at step  76000 :  5.82143510311842\n",
      "Average loss at step  78000 :  5.75977769267559\n",
      "Average loss at step  80000 :  5.869038049936295\n",
      "Average loss at step  82000 :  5.640153496742249\n",
      "Average loss at step  84000 :  5.594276427388191\n",
      "Average loss at step  86000 :  6.95049730682373\n",
      "Average loss at step  88000 :  5.407176083922386\n",
      "Average loss at step  90000 :  6.223182462215424\n",
      "Average loss at step  92000 :  5.202350311160088\n",
      "Average loss at step  94000 :  5.2701436011791225\n",
      "Average loss at step  96000 :  5.2287956169843675\n",
      "Average loss at step  98000 :  5.177702968895435\n",
      "Average loss at step  100000 :  5.0495376765727995\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100001 # Can increase \n",
    "log_dir = \"182/LSTMsAndInterpretability\"\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    writer = tf.summary.FileWriter(log_dir, session.graph)\n",
    "    \n",
    "    init.run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    average_loss = 0\n",
    "    for step in range(n_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size,\n",
    "                                                  data,\n",
    "                                                  num_skips,\n",
    "                                                  skip_window)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "        \n",
    "        run_metadata = tf.RunMetadata()\n",
    "    \n",
    "        _, summary, loss_val = session.run([optimizer, merged, loss],\n",
    "                                         feed_dict=feed_dict,\n",
    "                                         run_metadata=run_metadata)\n",
    "    \n",
    "        average_loss += loss_val\n",
    "    \n",
    "        if step % 5000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss /= 5000\n",
    "            # The average loss is an estimate of the loss over the last 5000\n",
    "            # batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss)\n",
    "            average_loss = 0\n",
    "            \n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "        \n",
    "    with open(log_dir + '/metadata.tsv', 'w') as f:\n",
    "        for i in range(n_words):\n",
    "            f.write(reversed_dictionary[i] + '\\n')\n",
    "        \n",
    "    saver.save(session, os.path.join(log_dir, 'model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.148621\n",
      "1.317841\n"
     ]
    }
   ],
   "source": [
    "cowboy = final_embeddings[vocab_dictionary['cowboy']]\n",
    "gun = final_embeddings[vocab_dictionary['gun']]\n",
    "random_word = final_embeddings[vocab_dictionary['building']]\n",
    "print(np.linalg.norm(cowboy - gun))\n",
    "print(np.linalg.norm(cowboy - random_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model embeddings so this part does not need to be run again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>2006</td>\n",
       "      <td>Stephanie Daley</td>\n",
       "      <td>American</td>\n",
       "      <td>Hilary Brougher</td>\n",
       "      <td>Amber Tamblyn, Tilda Swinton, Timothy Hutton</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stephanie_Daley</td>\n",
       "      <td>Sixteen-year-old Stephanie Daley collapses in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17686</th>\n",
       "      <td>2000</td>\n",
       "      <td>Dish, TheThe Dish</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Rob Sitch</td>\n",
       "      <td>Sam Neill\\r\\nPatrick Warburton\\r\\nTom Long\\r\\n...</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Dish</td>\n",
       "      <td>The radio telescope at Parkes (Parkes Observat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>1958</td>\n",
       "      <td>The Missouri Traveler</td>\n",
       "      <td>American</td>\n",
       "      <td>Jerry Hopper</td>\n",
       "      <td>Brandon deWilde, Lee Marvin</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Missouri_Tra...</td>\n",
       "      <td>Brandon deWilde leads a cast lengthy in charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>1977</td>\n",
       "      <td>Bhumika</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>Shyam Benegal</td>\n",
       "      <td>Smita Patil, Naseeruddin Shah, Amrish Puri</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bhumika_(1977_film)</td>\n",
       "      <td>Bhumika tells the life story of an actress, Us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12575</th>\n",
       "      <td>1995</td>\n",
       "      <td>To the Limit</td>\n",
       "      <td>American</td>\n",
       "      <td>Raymond Martino</td>\n",
       "      <td>Anna Nicole Smith, Michael Nouri</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/To_the_Limit_(19...</td>\n",
       "      <td>Anna Nicole Smith plays Vickie Lynn, an ex-CIA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                  Title Origin/Ethnicity         Director  \\\n",
       "15084          2006        Stephanie Daley         American  Hilary Brougher   \n",
       "17686          2000      Dish, TheThe Dish       Australian        Rob Sitch   \n",
       "7075           1958  The Missouri Traveler         American     Jerry Hopper   \n",
       "25002          1977                Bhumika        Bollywood    Shyam Benegal   \n",
       "12575          1995           To the Limit         American  Raymond Martino   \n",
       "\n",
       "                                                    Cast  Genre  \\\n",
       "15084       Amber Tamblyn, Tilda Swinton, Timothy Hutton  drama   \n",
       "17686  Sam Neill\\r\\nPatrick Warburton\\r\\nTom Long\\r\\n...  drama   \n",
       "7075                         Brandon deWilde, Lee Marvin  drama   \n",
       "25002         Smita Patil, Naseeruddin Shah, Amrish Puri  drama   \n",
       "12575                   Anna Nicole Smith, Michael Nouri  drama   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "15084      https://en.wikipedia.org/wiki/Stephanie_Daley   \n",
       "17686             https://en.wikipedia.org/wiki/The_Dish   \n",
       "7075   https://en.wikipedia.org/wiki/The_Missouri_Tra...   \n",
       "25002  https://en.wikipedia.org/wiki/Bhumika_(1977_film)   \n",
       "12575  https://en.wikipedia.org/wiki/To_the_Limit_(19...   \n",
       "\n",
       "                                                    Plot  \n",
       "15084  Sixteen-year-old Stephanie Daley collapses in ...  \n",
       "17686  The radio telescope at Parkes (Parkes Observat...  \n",
       "7075   Brandon deWilde leads a cast lengthy in charac...  \n",
       "25002  Bhumika tells the life story of an actress, Us...  \n",
       "12575  Anna Nicole Smith plays Vickie Lynn, an ex-CIA...  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(df, col, label_col=\"Label\"):\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[label_col] = df[col].cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = encodeLabel(train, \"Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot_words = train['Plot'].tolist()\n",
    "train_labels = train['Label'].tolist()\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode plots with word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(plot_list, final_embeddings):\n",
    "    plot_embeddings = []\n",
    "    \n",
    "    for plot in plot_list:\n",
    "    \n",
    "        embeddings = []\n",
    "    \n",
    "        p = multiple_replace(d, plot)\n",
    "    \n",
    "        all_words = p.split(\" \")\n",
    "    \n",
    "        for word in all_words:\n",
    "        \n",
    "            index = vocab_dictionary.get(word, 0)\n",
    "        \n",
    "            embedding = final_embeddings[index]\n",
    "            embeddings.append(embedding)\n",
    "            \n",
    "        plot_embeddings.append(embeddings)\n",
    "        \n",
    "    return plot_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-0c14cbd7ef0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_plot_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plot_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_plot_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_plot_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-288-5829524f1f95>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(plot_list, final_embeddings)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mplot_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/182/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4526\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4528\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_plot_embeddings = get_embeddings(train_plot_words, final_embeddings)\n",
    "train_plot_embeddings = np.array(train_plot_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_movies(batch_size, plots, labels):\n",
    "    # Assert ndarrays \n",
    "    \n",
    "    total = len(plots)\n",
    "    \n",
    "    indices = np.random.choice(total, batch_size, replace=False)\n",
    "    \n",
    "    batch_plots = np.take(plots, indices)\n",
    "    batch_labels = np.take(labels, indices)\n",
    "    \n",
    "    return batch_plots, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_plots, batch_labels = generate_batch_movies(20, train_plot_embeddings, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(batch_plots.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel():\n",
    "    \n",
    "    def __init__(self, rnn_size, output_size, learning_rate=1e-4):\n",
    "\n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, None, embedding_size])\n",
    "        self.labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    \n",
    "        lm_cell = tf.nn.rnn_cell.LSTMCell(rnn_size)\n",
    "    \n",
    "        outputs, states = tf.nn.dynamic_rnn(lm_cell, inputs, dtype=tf.float32)\n",
    "    \n",
    "        self.output_logits = tf.layers.dense(outputs, output_size)\n",
    "    \n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(self.labels, self.output_logits)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        \n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "        self.saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-252-b876f7b4b122>:8: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-252-b876f7b4b122>:10: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input tensor Tensor(\"Placeholder:0\", shape=(128,), dtype=int32) to have rank at least 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-bca7f3246141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is so that when you debug, you reset the graph each time you run this, in essence, cleaning the board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-252-b876f7b4b122>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rnn_size, output_size, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlm_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/182/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/182/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    632\u001b[0m           sequence_length, name=\"sequence_length\")\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_best_effort_input_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/182/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_best_effort_input_batch_size\u001b[0;34m(flat_input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       raise ValueError(\n\u001b[0;32m---> 92\u001b[0;31m           \"Expected input tensor %s to have rank at least 2\" % input_)\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input tensor Tensor(\"Placeholder:0\", shape=(128,), dtype=int32) to have rank at least 2"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # This is so that when you debug, you reset the graph each time you run this, in essence, cleaning the board\n",
    "model = LSTMModel(256, 7, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
